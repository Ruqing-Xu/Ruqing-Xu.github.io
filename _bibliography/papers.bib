---
---

@string{aps = {American Physical Society,}}


@article{xu2023decision,
  selected={true},
  abbr={arXiv},
  title={Decision-aid or Controller? Steering Human Decision Makers with Algorithms},
  abstract={Algorithms are used to aid human decision makers by making predictions and recommending decisions. Currently, these algorithms are trained to optimize prediction accuracy. What if they were optimized to control final decisions? In this paper, we study a decision-aid algorithm that learns about the human decision maker and provides ``personalized recommendations'' to influence final decisions. We first consider fixed human decision functions which map observable features and the algorithm's recommendations to final decisions. We characterize the conditions under which perfect control over final decisions is attainable. Under fairly general assumptions, the parameters of the human decision function can be identified from past interactions between the algorithm and the human decision maker, even when the algorithm was constrained to make truthful recommendations. We then consider a decision maker who is aware of the algorithm's manipulation and responds strategically. By posing the setting as a variation of the cheap talk game [Crawford and Sobel, 1982], we show that all equilibria are partition equilibria where only coarse information is shared: the algorithm recommends an interval containing the ideal decision. We discuss the potential applications of such algorithms and their social implications.},
  author={Xu, Ruqing and Dean, Sarah},
  journal={arXiv preprint},
  year={2023},
  arxiv={2303.13712},
  pdf={decision_paper.pdf},
  slides={decision_presentation.pdf}
}

@article{enem2023,
  selected={true},
  title={Stakes and Signals: An Empirical Investigation of Muddled Information in Standardized Testing},
  abstract={Muddled information models posit that higher stakes increase a signal's informativeness about individuals' <em>gaming ability</em> and decrease its informativeness for their <em>natural ability</em>. An important question is whether this muddling of abilities degrades the predictive value of a signal for long-run outcomes. We evaluate this question in the context of standardized testing by exploiting the introduction of Brazil's national college admission exam, the ENEM. The staggered adoption of the ENEM by universities meant that, depending on their location and cohort, students either took a low-stakes school accountability test or a high-stakes test that governed admission to the most selective colleges in their area. Using ENEM records linked to nationwide college and labor market data, we find that the increase in the stakes of the ENEM exam made scores <em>more</em> informative for students' longer-run outcomes. However, test score gaps between high- and lower-income students also expanded on the higher-stakes ENEM exam. Our results show that signals that include gaming ability can be more informative about individual productivity than signals that measure only natural ability, but they can also exacerbate socioeconomic inequality.},
  author={Reyes*, Germ\'{a}n and Riehl*, Evan and Xu*, Ruqing},
  journal={Working paper},
  year={2023},
  pdf={rrx_stakes_oct2023.pdf}
}

@article{xu2023delegation,
  selected={true},
  title={Persuasion, Delegation, and Private Information},
  abstract={A principal designs an information structure that generates a publicly observable signal. The principal also decides whether to take an action directly with the public signal, or to delegate the decision to an agent who also observes a private signal but may be biased. We consider the joint design of optimal persuasion and delegation mechanisms in such environments. We find that the principal strictly prefers delegation if and only if the agent's potential posteriors fall on both sides of the "disagreement interval." Then, we derive comparative statics results regarding the informativeness of the agent's signal and the degree of preference misalignment between the players. These results have important implications for the design of algorithm-assisted decisions, where for example, algorithms may provide recommendations to and restrict the actions of human experts, who have private information but may be biased.},
  author={Xu, Ruqing},
  journal={Work in progress},
  year={2023},
  slides={delegation_slides.pdf}
}

