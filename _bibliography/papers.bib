---
---

@string{aps = {American Physical Society,}}

@article{xu2023delegation,
  selected={true},
  abbr={arXiv},
  title={Persuasion, Delegation, and Private Information in Algorithm-Assisted Decisions},
  abstract={A principal designs an algorithm that generates a publicly observable prediction of a binary state. She must decide whether to act directly based on the prediction or to delegate the decision to an agent with private information but potential misalignment. We study the optimal design of the prediction algorithm and the delegation rule in such environments. Three key findings emerge: (1)  Delegation is optimal if and only if the principal would make the same binary decision as the agent had she observed the agent's information. (2) Providing the most informative algorithm may be suboptimal even if the principal can act on the algorithm's prediction. Instead, the optimal algorithm may provide more information about one state and restrict information about the other. (3) Well-intentioned policies aiming to provide more information, such as keeping a ``human-in-the-loop'' or requiring maximal prediction accuracy, could strictly worsen decision quality compared to systems with no human or no algorithmic assistance. These findings predict the underperformance of human-machine collaborations if no measures are taken to mitigate common preference misalignment between algorithms and human decision-makers.},
  author={Xu, Ruqing},
  journal={Working paper},
  year={2024},
  arxiv={2402.09384},
  pdf={delegation_xu.pdf}
}

@article{enem2023,
  selected={true},
  abbr={Working Paper},
  title={Stakes and Signals: An Empirical Investigation of Muddled Information in Standardized Testing},
  abstract={We examine a natural experiment in Brazil in which similar students took the same standardized test as either a low-stakes school accountability exam or a high- stakes admission exam for the country's top universities. Using administrative data and a difference-in-differences design, we find that test score gaps between high- and low-income students expanded on the high-stakes exam, consistent with wealthy students engaging in test prep. Yet the increase in stakes made scores more informative for students' college outcomes. Thus the ``muddling'' of information on natural ability and test prep improved the quality of the score signal, although it also exacerbated inequality.},
  author={Reyes*, Germ\'{a}n and Riehl*, Evan and Xu*, Ruqing},
  journal={Working paper},
  year={2024},
  pdf={rrx_stakes_june2024.pdf}
}

@article{xu2023decision,
  selected={true},
  abbr={arXiv},
  title={Decision-aid or Controller? Steering Human Decision Makers with Algorithms},
  abstract={Algorithms are used to aid human decision makers by making predictions and recommending decisions. Currently, these algorithms are trained to optimize prediction accuracy. What if they were optimized to control final decisions? In this paper, we study a decision-aid algorithm that learns about the human decision maker and provides ``personalized recommendations'' to influence final decisions. We first consider fixed human decision functions which map observable features and the algorithm's recommendations to final decisions. We characterize the conditions under which perfect control over final decisions is attainable. Under fairly general assumptions, the parameters of the human decision function can be identified from past interactions between the algorithm and the human decision maker, even when the algorithm was constrained to make truthful recommendations. We then consider a decision maker who is aware of the algorithm's manipulation and responds strategically. By posing the setting as a variation of the cheap talk game [Crawford and Sobel, 1982], we show that all equilibria are partition equilibria where only coarse information is shared: the algorithm recommends an interval containing the ideal decision. We discuss the potential applications of such algorithms and their social implications.},
  author={Xu, Ruqing and Dean, Sarah},
  journal={Working paper},
  year={2023},
  arxiv={2303.13712},
  pdf={decision_paper.pdf},
  slides={decision_presentation.pdf}
}




